{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f141af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from dartorch.models.mvconv import MultiViewConvBackbone, MultiFrameFeatureMixer, Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84133f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiViewConvBackbone(\n",
      "  (conv1): Conv2DNormActivation(\n",
      "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6()\n",
      "  )\n",
      "  (res2): Conv2DResidualBlock(\n",
      "    (activation): ReLU6()\n",
      "    (conv1): Conv2DNormActivation(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU6()\n",
      "    )\n",
      "    (conv2): Conv2DNormActivation(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    )\n",
      "  )\n",
      "  (res3): Conv2DResidualBlock(\n",
      "    (activation): ReLU6()\n",
      "    (conv1): Conv2DNormActivation(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6()\n",
      "    )\n",
      "    (conv2): Conv2DNormActivation(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (attn_3): SelfAttention2d(\n",
      "    (query_conv): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (key_conv): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (value_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (res4): Conv2DResidualBlock(\n",
      "    (activation): ReLU6()\n",
      "    (conv1): Conv2DNormActivation(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): ReLU6()\n",
      "    )\n",
      "    (conv2): Conv2DNormActivation(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    )\n",
      "    (projection): Conv2DNormActivation(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (res5): Conv2DResidualBlock(\n",
      "    (activation): ReLU6()\n",
      "    (conv1): Conv2DNormActivation(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU6()\n",
      "    )\n",
      "    (conv2): Conv2DNormActivation(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    )\n",
      "  )\n",
      "  (res6): Conv2DResidualBlock(\n",
      "    (activation): ReLU6()\n",
      "    (conv1): Conv2DNormActivation(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6()\n",
      "    )\n",
      "    (conv2): Conv2DNormActivation(\n",
      "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (attn_6): SelfAttention2d(\n",
      "    (query_conv): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (key_conv): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (value_conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (res7): Conv2DResidualBlock(\n",
      "    (activation): ReLU6()\n",
      "    (conv1): Conv2DNormActivation(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): ReLU6()\n",
      "    )\n",
      "    (conv2): Conv2DNormActivation(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    )\n",
      "    (projection): Conv2DNormActivation(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (res8): Conv2DResidualBlock(\n",
      "    (activation): ReLU6()\n",
      "    (conv1): Conv2DNormActivation(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU6()\n",
      "    )\n",
      "    (conv2): Conv2DNormActivation(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    )\n",
      "  )\n",
      "  (res9): Conv2DResidualBlock(\n",
      "    (activation): ReLU6()\n",
      "    (conv1): Conv2DNormActivation(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6()\n",
      "    )\n",
      "    (conv2): Conv2DNormActivation(\n",
      "      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (attn_9): SelfAttention2d(\n",
      "    (query_conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (key_conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (value_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (res10): Conv2DResidualBlock(\n",
      "    (activation): ReLU6()\n",
      "    (conv1): Conv2DNormActivation(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): ReLU6()\n",
      "    )\n",
      "    (conv2): Conv2DNormActivation(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    )\n",
      "    (projection): Conv2DNormActivation(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (res11): Conv2DResidualBlock(\n",
      "    (activation): ReLU6()\n",
      "    (conv1): Conv2DNormActivation(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU6()\n",
      "    )\n",
      "    (conv2): Conv2DNormActivation(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    )\n",
      "  )\n",
      "  (res12): Conv2DResidualBlock(\n",
      "    (activation): ReLU6()\n",
      "    (conv1): Conv2DNormActivation(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6()\n",
      "    )\n",
      "    (conv2): Conv2DNormActivation(\n",
      "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (attn_12): SelfAttention2d(\n",
      "    (query_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (key_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (value_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (softmax): Softmax(dim=-1)\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=(8, 8), stride=(8, 8), padding=0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MultiViewConvBackbone(in_size=(128, 128))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f367491b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MultiViewConvBackbone                    --                        --\n",
       "├─Conv2DNormActivation: 1-1              [5, 64, 64, 64]           --\n",
       "│    └─Conv2d: 2-1                       [5, 64, 64, 64]           4,864\n",
       "│    └─BatchNorm2d: 2-2                  [5, 64, 64, 64]           128\n",
       "│    └─ReLU6: 2-3                        [5, 64, 64, 64]           --\n",
       "├─Conv2DResidualBlock: 1-2               [5, 64, 64, 64]           --\n",
       "│    └─Conv2DNormActivation: 2-4         [5, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-1                  [5, 64, 64, 64]           36,928\n",
       "│    │    └─ReLU6: 3-2                   [5, 64, 64, 64]           --\n",
       "│    └─Conv2DNormActivation: 2-5         [5, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-3                  [5, 64, 64, 64]           36,928\n",
       "│    └─ReLU6: 2-6                        [5, 64, 64, 64]           --\n",
       "├─Conv2DResidualBlock: 1-3               [5, 64, 64, 64]           --\n",
       "│    └─Conv2DNormActivation: 2-7         [5, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-4                  [5, 64, 64, 64]           36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [5, 64, 64, 64]           128\n",
       "│    │    └─ReLU6: 3-6                   [5, 64, 64, 64]           --\n",
       "│    └─Conv2DNormActivation: 2-8         [5, 64, 64, 64]           --\n",
       "│    │    └─Conv2d: 3-7                  [5, 64, 64, 64]           36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [5, 64, 64, 64]           128\n",
       "│    └─ReLU6: 2-9                        [5, 64, 64, 64]           --\n",
       "├─SelfAttention2d: 1-4                   [5, 64, 64, 64]           --\n",
       "│    └─Conv2d: 2-10                      [5, 8, 64, 64]            520\n",
       "│    └─Conv2d: 2-11                      [5, 8, 64, 64]            520\n",
       "│    └─Softmax: 2-12                     [5, 4096, 4096]           --\n",
       "│    └─Conv2d: 2-13                      [5, 64, 64, 64]           4,160\n",
       "├─Conv2DResidualBlock: 1-5               [5, 128, 32, 32]          --\n",
       "│    └─Conv2DNormActivation: 2-14        [5, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-9                  [5, 128, 32, 32]          73,856\n",
       "│    │    └─ReLU6: 3-10                  [5, 128, 32, 32]          --\n",
       "│    └─Conv2DNormActivation: 2-15        [5, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-11                 [5, 128, 32, 32]          147,584\n",
       "│    └─Conv2DNormActivation: 2-16        [5, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-12                 [5, 128, 32, 32]          8,192\n",
       "│    └─ReLU6: 2-17                       [5, 128, 32, 32]          --\n",
       "├─Conv2DResidualBlock: 1-6               [5, 128, 32, 32]          --\n",
       "│    └─Conv2DNormActivation: 2-18        [5, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-13                 [5, 128, 32, 32]          147,584\n",
       "│    │    └─ReLU6: 3-14                  [5, 128, 32, 32]          --\n",
       "│    └─Conv2DNormActivation: 2-19        [5, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-15                 [5, 128, 32, 32]          147,584\n",
       "│    └─ReLU6: 2-20                       [5, 128, 32, 32]          --\n",
       "├─Conv2DResidualBlock: 1-7               [5, 128, 32, 32]          --\n",
       "│    └─Conv2DNormActivation: 2-21        [5, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-16                 [5, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d: 3-17            [5, 128, 32, 32]          256\n",
       "│    │    └─ReLU6: 3-18                  [5, 128, 32, 32]          --\n",
       "│    └─Conv2DNormActivation: 2-22        [5, 128, 32, 32]          --\n",
       "│    │    └─Conv2d: 3-19                 [5, 128, 32, 32]          147,456\n",
       "│    │    └─BatchNorm2d: 3-20            [5, 128, 32, 32]          256\n",
       "│    └─ReLU6: 2-23                       [5, 128, 32, 32]          --\n",
       "├─SelfAttention2d: 1-8                   [5, 128, 32, 32]          --\n",
       "│    └─Conv2d: 2-24                      [5, 16, 32, 32]           2,064\n",
       "│    └─Conv2d: 2-25                      [5, 16, 32, 32]           2,064\n",
       "│    └─Softmax: 2-26                     [5, 1024, 1024]           --\n",
       "│    └─Conv2d: 2-27                      [5, 128, 32, 32]          16,512\n",
       "├─Conv2DResidualBlock: 1-9               [5, 256, 16, 16]          --\n",
       "│    └─Conv2DNormActivation: 2-28        [5, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-21                 [5, 256, 16, 16]          295,168\n",
       "│    │    └─ReLU6: 3-22                  [5, 256, 16, 16]          --\n",
       "│    └─Conv2DNormActivation: 2-29        [5, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-23                 [5, 256, 16, 16]          590,080\n",
       "│    └─Conv2DNormActivation: 2-30        [5, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-24                 [5, 256, 16, 16]          32,768\n",
       "│    └─ReLU6: 2-31                       [5, 256, 16, 16]          --\n",
       "├─Conv2DResidualBlock: 1-10              [5, 256, 16, 16]          --\n",
       "│    └─Conv2DNormActivation: 2-32        [5, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-25                 [5, 256, 16, 16]          590,080\n",
       "│    │    └─ReLU6: 3-26                  [5, 256, 16, 16]          --\n",
       "│    └─Conv2DNormActivation: 2-33        [5, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-27                 [5, 256, 16, 16]          590,080\n",
       "│    └─ReLU6: 2-34                       [5, 256, 16, 16]          --\n",
       "├─Conv2DResidualBlock: 1-11              [5, 256, 16, 16]          --\n",
       "│    └─Conv2DNormActivation: 2-35        [5, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-28                 [5, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-29            [5, 256, 16, 16]          512\n",
       "│    │    └─ReLU6: 3-30                  [5, 256, 16, 16]          --\n",
       "│    └─Conv2DNormActivation: 2-36        [5, 256, 16, 16]          --\n",
       "│    │    └─Conv2d: 3-31                 [5, 256, 16, 16]          589,824\n",
       "│    │    └─BatchNorm2d: 3-32            [5, 256, 16, 16]          512\n",
       "│    └─ReLU6: 2-37                       [5, 256, 16, 16]          --\n",
       "├─SelfAttention2d: 1-12                  [5, 256, 16, 16]          --\n",
       "│    └─Conv2d: 2-38                      [5, 32, 16, 16]           8,224\n",
       "│    └─Conv2d: 2-39                      [5, 32, 16, 16]           8,224\n",
       "│    └─Softmax: 2-40                     [5, 256, 256]             --\n",
       "│    └─Conv2d: 2-41                      [5, 256, 16, 16]          65,792\n",
       "├─Conv2DResidualBlock: 1-13              [5, 512, 8, 8]            --\n",
       "│    └─Conv2DNormActivation: 2-42        [5, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-33                 [5, 512, 8, 8]            1,180,160\n",
       "│    │    └─ReLU6: 3-34                  [5, 512, 8, 8]            --\n",
       "│    └─Conv2DNormActivation: 2-43        [5, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-35                 [5, 512, 8, 8]            2,359,808\n",
       "│    └─Conv2DNormActivation: 2-44        [5, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-36                 [5, 512, 8, 8]            131,072\n",
       "│    └─ReLU6: 2-45                       [5, 512, 8, 8]            --\n",
       "├─Conv2DResidualBlock: 1-14              [5, 512, 8, 8]            --\n",
       "│    └─Conv2DNormActivation: 2-46        [5, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-37                 [5, 512, 8, 8]            2,359,808\n",
       "│    │    └─ReLU6: 3-38                  [5, 512, 8, 8]            --\n",
       "│    └─Conv2DNormActivation: 2-47        [5, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-39                 [5, 512, 8, 8]            2,359,808\n",
       "│    └─ReLU6: 2-48                       [5, 512, 8, 8]            --\n",
       "├─Conv2DResidualBlock: 1-15              [5, 512, 8, 8]            --\n",
       "│    └─Conv2DNormActivation: 2-49        [5, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-40                 [5, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-41            [5, 512, 8, 8]            1,024\n",
       "│    │    └─ReLU6: 3-42                  [5, 512, 8, 8]            --\n",
       "│    └─Conv2DNormActivation: 2-50        [5, 512, 8, 8]            --\n",
       "│    │    └─Conv2d: 3-43                 [5, 512, 8, 8]            2,359,296\n",
       "│    │    └─BatchNorm2d: 3-44            [5, 512, 8, 8]            1,024\n",
       "│    └─ReLU6: 2-51                       [5, 512, 8, 8]            --\n",
       "├─SelfAttention2d: 1-16                  [5, 512, 8, 8]            --\n",
       "│    └─Conv2d: 2-52                      [5, 64, 8, 8]             32,832\n",
       "│    └─Conv2d: 2-53                      [5, 64, 8, 8]             32,832\n",
       "│    └─Softmax: 2-54                     [5, 64, 64]               --\n",
       "│    └─Conv2d: 2-55                      [5, 512, 8, 8]            262,656\n",
       "├─AvgPool2d: 1-17                        [5, 512, 1, 1]            --\n",
       "==========================================================================================\n",
       "Total params: 17,799,600\n",
       "Trainable params: 17,799,600\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 16.13\n",
       "==========================================================================================\n",
       "Input size (MB): 0.98\n",
       "Forward/backward pass size (MB): 191.04\n",
       "Params size (MB): 71.20\n",
       "Estimated Total Size (MB): 263.22\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, (1, 15, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aadacd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_model = MultiFrameFeatureMixer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "079ad8dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MultiFrameFeatureMixer                   --                        --\n",
       "├─ConvNormActivation1d: 1-1              [1, 16, 512]              --\n",
       "│    └─Conv1d: 2-1                       [1, 16, 512]              416\n",
       "│    └─ReLU6: 2-2                        [1, 16, 512]              --\n",
       "├─ConvNormActivation1d: 1-2              [1, 64, 512]              --\n",
       "│    └─Conv1d: 2-3                       [1, 64, 512]              3,072\n",
       "│    └─BatchNorm1d: 2-4                  [1, 64, 512]              128\n",
       "│    └─ReLU6: 2-5                        [1, 64, 512]              --\n",
       "├─SelfAttention1d: 1-3                   [1, 64, 512]              --\n",
       "│    └─Conv1d: 2-6                       [1, 8, 512]               520\n",
       "│    └─Conv1d: 2-7                       [1, 8, 512]               520\n",
       "│    └─Softmax: 2-8                      [1, 512, 512]             --\n",
       "│    └─Conv1d: 2-9                       [1, 64, 512]              4,160\n",
       "├─ConvResidualBlock1d: 1-4               [1, 128, 256]             --\n",
       "│    └─ConvNormActivation1d: 2-10        [1, 128, 256]             --\n",
       "│    │    └─Conv1d: 3-1                  [1, 128, 256]             24,704\n",
       "│    │    └─ReLU6: 3-2                   [1, 128, 256]             --\n",
       "│    └─ConvNormActivation1d: 2-11        [1, 128, 256]             --\n",
       "│    │    └─Conv1d: 3-3                  [1, 128, 256]             49,280\n",
       "│    └─ConvNormActivation1d: 2-12        [1, 128, 256]             --\n",
       "│    │    └─Conv1d: 3-4                  [1, 128, 256]             8,192\n",
       "│    └─ReLU6: 2-13                       [1, 128, 256]             --\n",
       "├─ConvResidualBlock1d: 1-5               [1, 128, 128]             --\n",
       "│    └─ConvNormActivation1d: 2-14        [1, 128, 128]             --\n",
       "│    │    └─Conv1d: 3-5                  [1, 128, 128]             49,152\n",
       "│    │    └─BatchNorm1d: 3-6             [1, 128, 128]             256\n",
       "│    │    └─ReLU6: 3-7                   [1, 128, 128]             --\n",
       "│    └─ConvNormActivation1d: 2-15        [1, 128, 128]             --\n",
       "│    │    └─Conv1d: 3-8                  [1, 128, 128]             49,152\n",
       "│    │    └─BatchNorm1d: 3-9             [1, 128, 128]             256\n",
       "│    └─ConvNormActivation1d: 2-16        [1, 128, 128]             --\n",
       "│    │    └─Conv1d: 3-10                 [1, 128, 128]             16,384\n",
       "│    └─ReLU6: 2-17                       [1, 128, 128]             --\n",
       "├─SelfAttention1d: 1-6                   [1, 128, 128]             --\n",
       "│    └─Conv1d: 2-18                      [1, 16, 128]              2,064\n",
       "│    └─Conv1d: 2-19                      [1, 16, 128]              2,064\n",
       "│    └─Softmax: 2-20                     [1, 128, 128]             --\n",
       "│    └─Conv1d: 2-21                      [1, 128, 128]             16,512\n",
       "├─ConvResidualBlock1d: 1-7               [1, 128, 64]              --\n",
       "│    └─ConvNormActivation1d: 2-22        [1, 128, 64]              --\n",
       "│    │    └─Conv1d: 3-11                 [1, 128, 64]              49,280\n",
       "│    │    └─ReLU6: 3-12                  [1, 128, 64]              --\n",
       "│    └─ConvNormActivation1d: 2-23        [1, 128, 64]              --\n",
       "│    │    └─Conv1d: 3-13                 [1, 128, 64]              49,280\n",
       "│    └─ConvNormActivation1d: 2-24        [1, 128, 64]              --\n",
       "│    │    └─Conv1d: 3-14                 [1, 128, 64]              16,384\n",
       "│    └─ReLU6: 2-25                       [1, 128, 64]              --\n",
       "├─ConvResidualBlock1d: 1-8               [1, 128, 32]              --\n",
       "│    └─ConvNormActivation1d: 2-26        [1, 128, 32]              --\n",
       "│    │    └─Conv1d: 3-15                 [1, 128, 32]              49,152\n",
       "│    │    └─BatchNorm1d: 3-16            [1, 128, 32]              256\n",
       "│    │    └─ReLU6: 3-17                  [1, 128, 32]              --\n",
       "│    └─ConvNormActivation1d: 2-27        [1, 128, 32]              --\n",
       "│    │    └─Conv1d: 3-18                 [1, 128, 32]              49,152\n",
       "│    │    └─BatchNorm1d: 3-19            [1, 128, 32]              256\n",
       "│    └─ConvNormActivation1d: 2-28        [1, 128, 32]              --\n",
       "│    │    └─Conv1d: 3-20                 [1, 128, 32]              16,384\n",
       "│    └─ReLU6: 2-29                       [1, 128, 32]              --\n",
       "├─SelfAttention1d: 1-9                   [1, 128, 32]              --\n",
       "│    └─Conv1d: 2-30                      [1, 16, 32]               2,064\n",
       "│    └─Conv1d: 2-31                      [1, 16, 32]               2,064\n",
       "│    └─Softmax: 2-32                     [1, 32, 32]               --\n",
       "│    └─Conv1d: 2-33                      [1, 128, 32]              16,512\n",
       "├─ConvResidualBlock1d: 1-10              [1, 128, 16]              --\n",
       "│    └─ConvNormActivation1d: 2-34        [1, 128, 16]              --\n",
       "│    │    └─Conv1d: 3-21                 [1, 128, 16]              49,280\n",
       "│    │    └─ReLU6: 3-22                  [1, 128, 16]              --\n",
       "│    └─ConvNormActivation1d: 2-35        [1, 128, 16]              --\n",
       "│    │    └─Conv1d: 3-23                 [1, 128, 16]              49,280\n",
       "│    └─ConvNormActivation1d: 2-36        [1, 128, 16]              --\n",
       "│    │    └─Conv1d: 3-24                 [1, 128, 16]              16,384\n",
       "│    └─ReLU6: 2-37                       [1, 128, 16]              --\n",
       "├─AvgPool1d: 1-11                        [1, 128, 1]               --\n",
       "==========================================================================================\n",
       "Total params: 592,560\n",
       "Trainable params: 592,560\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 56.33\n",
       "==========================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 2.97\n",
       "Params size (MB): 2.37\n",
       "Estimated Total Size (MB): 5.35\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(fm_model, (1, 5, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bad70b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_model = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "458547e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Classifier                               --                        --\n",
       "├─Linear: 1-1                            [1, 256]                  33,024\n",
       "├─ReLU6: 1-2                             [1, 256]                  --\n",
       "├─Linear: 1-3                            [1, 512]                  131,072\n",
       "├─ReLU6: 1-4                             [1, 512]                  --\n",
       "├─BatchNorm1d: 1-5                       [1, 512]                  1,024\n",
       "├─Linear: 1-6                            [1, 128]                  65,664\n",
       "├─ReLU6: 1-7                             [1, 128]                  --\n",
       "├─Linear: 1-8                            [1, 64]                   8,192\n",
       "├─ReLU6: 1-9                             [1, 64]                   --\n",
       "├─BatchNorm1d: 1-10                      [1, 64]                   128\n",
       "├─Linear: 1-11                           [1, 16]                   1,040\n",
       "├─ReLU6: 1-12                            [1, 16]                   --\n",
       "├─Linear: 1-13                           [1, 8]                    136\n",
       "├─Softmax: 1-14                          [1, 8]                    --\n",
       "==========================================================================================\n",
       "Total params: 240,280\n",
       "Trainable params: 240,280\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.24\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.01\n",
       "Params size (MB): 0.96\n",
       "Estimated Total Size (MB): 0.97\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(cl_model, (1, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b8cb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77286fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
